:toc:

= Docker Workshop

This repository consists of notes, links and examples for learning the basics of Docker.

These are the main sources I used in creating this workshop:

* https://www.udemy.com/course/docker-for-java-developers/[Udemy workshop Docker for Java Developers by John
Thompson]. Johns Docker Cheat Sheet can be found https://springframework.guru/docker-cheat-sheet-for-spring-devlopers/[here].
* https://github.com/msgoat/cxp-dox-home/[Cloud Expert Program of msg].
* https://www.udemy.com/course/docker-mastery/[Docker Mastery: with Kubernetes +Swarm from a Docker Captain],
https://github.com/bretfisher/udemy-docker-mastery[examples on Github]
* https://docs.docker.com[docs.docker.com], the official documentation

The course may be used for learning Docker on your own or facilitating workshops.

== Setup for this Workshop

**Before** this workshop, please setup docker and the Amazon CLI.

=== Install Docker

Docker install can be done in multiple ways, for example via https://docs.docker.com/desktop/windows/install/[Docker Desktop], https://docs.microsoft.com/de-de/windows/wsl/tutorials/wsl-containers[Windows Subsystem for Linux] or just https://docs.docker.com/engine/install/ubuntu/[using a Linux and installing Docker]. It is recommended to use a (relatively) native environment such as WSL with Ubuntu.

Test if the installation was successful by running

----
$ docker --version
----

You should see something like

----
Docker version 20.10.8, build 3967b7d
----

=== Install Amazon CLI

Use the https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html[official User Guide] to install
the CLI on your machine.

After successful installation, try running

----
C:\> aws --version
----

You should see something like

----
aws-cli/2.3.7 Python/3.8.8 Windows/10 exe/AMD64 prompt/off
----

== Why Docker

=== Some Convenience Examples for Developers

Here are some examples of how Docker can be used in the context of developing software.

Want to use another operating system? Try Ubuntu or Debian with:
----
$ docker run -it --name="ubuntu" ubuntu bash
----
----
$ docker run -it --name="debian" debian bash
----

Want to draw nice graphs without installing Draw.io?
----
$ docker run -it --name="draw-io" -p 8080:8080 -p 8443:8443 jgraph/drawio
----

Docker can also be used to https://www.codemag.com/article/1811021/Docker-for-Developers[setup your whole working environment].

And here's https://awesome-docker.netlify.app[curated list of Docker resources and projects].

=== Some History

* one of the major shifts in IT:
** 90's Mainframe to PC
** 00's Baremetal to Virtual
** 10's Datacenter to Cloud
** ~2015 Host to Container (Docker, Serverless)
* containers reduce complexity because only infrastructure for running containers has to be provided, not every
specific setup detail
* containers allow exactly same setup for development, testing and production


== New and Old Command Line Structure

Structure of commands changed.

* old (still working):
----
docker <command> (options)
----
** new:
----
docker <command> <subcommand> (options)
----
* old example:
----
docker run
----
** new example:
----
docker container run
----


== Fundamental Concepts

* **Docker-Daemon** runs in Linux kernel and is the base for Docker images to run on
* **image** = set of layers based on a base-image ("from scratch") that describe an environment that can be run
* **container** = running instance of an image
* many containers can run same image
* **registry** = where images can be downloaded. https://hub.docker.com[Docker Hub] is for containers what Github is
for source code: remote
Docker images are downloaded into local repository to be used.
* difference between Docker and virtual machines (VMs): Docker needs less resources and has a very low boot-up-time, hence creating and discarding containers in great numbers possible with Docker, but not VMs


== Starting, Stopping and Deleting Containers and Images
The following series of commands is designed to be executed in the order given below.

=== Get general information about Docker installation
----
docker info
----

=== Starting A Container From Existing Image
----
docker container run -p 80:80 --name first-container nginx
----

* will download needed images from remote docker repository
* in browser at localhost:80 welcome-page of nginx
* also, directly within terminal 'curl localhost: 80'
* will block current terminal
* -p for --publish. Means that port 80 from within container is forwarded to 80 of local machine. Syntax: left-hand =
local machine, right-hand = port in container. Example: 8080:80 means that local machine port 8080 is equal to port
80 in container.
* -- name specifies name; if left, Docker generates name

=== List Running Containers
----
docker container ls
----

* has to be run in new terminal because first terminal should be blocked with run-command
* should list formerly started 'first-container'
* old command 'docker ps'


=== Stop Running Container
----
docker container stop first-container
----

* running 'docker ps' again will show it is stopped

=== Restart Existing Container
----
docker container start first-container
----

* will not block current terminal
* https://stackoverflow.com/questions/34782678/difference-between-running-and-starting-a-docker-container[difference between run und start]:
** 'run' is 'docker create', which creates a container from an image which is downloaded if not existing locally,
plus 'docker start'
** 'start' launches previously stopped container with same settings. Opposite to "stop".

=== Stop Running Container (again)
----
docker container stop first-container
----

=== List All Containers
----
docker container ls -a
----
* lists all containers, even exited (exit-code 0)
* should show container 'first-container'

=== Remove Container
----
docker container rm first-container
----
* will delete formerly created 'first-container'

=== List All Images
----
docker image ls
----
* image for nginx still present in local repository

=== Remove Image
----
docker image rm nginx
----
* will delete image for nginx from **local** repository

=== Trying to 'start' Non-Existing Container
----
docker container start nginx
----
* will result in error because image nginx is not present in local repository and has to be downloaded again, for
example with 'docker run'

=== Some Tweaks for this Section
The examples above can be tweaked a little with the following concepts.

==== Destroying Container After Usage
----
docker container run -p 80:80 --name first-container --rm nginx
----
* '--rm' will destroy and delete the container after it has been run
* useful for short demonstrations where the container is not needed afterwards

==== Running Container in Background as a Daemon
----
docker container run -p 80:80 --name first-container -d nginx
----
* "docker run" runs interactively. To run as daemon in background, use --detach or -d

==== Referencing Containers With Container ID
* make sure to have a container named 'first-container' (and did not delete it)
* then run:
----
docker container start first-container
docker container ls
----
* 'ls' should print something like this:
----
CONTAINER ID   IMAGE     COMMAND                  CREATED         STATUS         PORTS                NAMES
f67316fc16c3   nginx     "/docker-entrypoint.â€¦"   4 seconds ago   Up 4 seconds   0.0.0.0:80->80/tcp   first-container
----
* to stop this container, you may reference the container ID like this (instead of the name):
----
docker container stop f6
----

==== Cleaning Up
----
docker container rm -f f6 a1 0d
----
* will remove containers with IDs beginning with 'f6', 'a1' and '0d', even if they are running (will be stopped)


== Logs
=== (Re-)Creating Our Container to Test
----
docker container run -p 80:80 --name first-container -d nginx
----

=== Show Logs
----
docker container logs first-container
----
* shows only the logs created up until now

=== Show Logs and Follow
----
docker container logs -f first-container
----
* Refresh nginx-page in browser and see how requests are logged
* leave with Ctrl + c

== Getting Information
=== Processes
In Linux, 'top' shows running processes:
----
top
----
----
%Cpu(s):  0.0 us,  0.1 sy,  0.0 ni, 99.9 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
MiB Mem :  25490.2 total,  23489.3 free,    599.1 used,   1401.7 buff/cache
MiB Swap:   7168.0 total,   7168.0 free,      0.0 used.  24195.6 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
    1 root      20   0    1052    664    524 S   0.0   0.0   0:01.05 init
  111 root      20   0     892     84     20 S   0.0   0.0   0:00.00 init
  112 root      20   0     892     84     20 S   0.0   0.0   0:00.04 init
  113 root      20   0 1753032  29360  13152 S   0.0   0.1   0:02.22 docker-desktop-
  122 root      20   0     892     84     20 S   0.0   0.0   0:00.00 init
  123 stevens+  20   0  765524  42732  29364 S   0.0   0.2   0:02.64 docker
  162 root      20   0     900     92     20 S   0.0   0.0   0:00.00 init
  163 root      20   0     900     92     20 S   0.0   0.0   0:00.11 init
  164 stevens+  20   0   10160   5256   3424 S   0.0   0.0   0:00.12 bash
 2104 root      20   0    1040    216     20 S   0.0   0.0   0:00.00 init
 2105 root      20   0    1040    216     20 S   0.0   0.0   0:00.36 init
 2106 stevens+  20   0   10164   5220   3448 S   0.0   0.0   0:00.27 bash
12469 stevens+  20   0   10884   3736   3136 R   0.0   0.0   0:00.00 top
----

Also available for running Docker containers:
----
docker container top first-container
----
----
UID                 PID                 PPID                C                   STIME               TTY                 TIME                CMD
root                3118                3097                0                   08:50               ?                   00:00:00            nginx: master process nginx -g daemon off;
uuidd               3167                3118                0                   08:50               ?                   00:00:00            nginx: worker process
uuidd               3168                3118                0                   08:50               ?                   00:00:00            nginx: worker process
uuidd               3169                3118                0                   08:50               ?                   00:00:00            nginx: worker process
uuidd               3170                3118                0                   08:50               ?                   00:00:00            nginx: worker process
uuidd               3171                3118                0                   08:50               ?                   00:00:00            nginx: worker process
uuidd               3172                3118                0                   08:50               ?                   00:00:00            nginx: worker process
uuidd               3173                3118                0                   08:50               ?                   00:00:00            nginx: worker process
uuidd               3174                3118                0                   08:50               ?                   00:00:00            nginx: worker process
uuidd               3175                3118                0                   08:50               ?                   00:00:00            nginx: worker process
uuidd               3176                3118                0                   08:50               ?                   00:00:00            nginx: worker process
uuidd               3177                3118                0                   08:50               ?                   00:00:00            nginx: worker process
uuidd               3178                3118                0                   08:50               ?                   00:00:00            nginx: worker process
stevenschwenke@msgn13623:/mnt/c/Users/schwenks$ yc
----

=== Meta-Data
----
docker container inspect first-container
----

=== Live Performance Data
----
docker container stats
----
* for all container statistics


== Getting Inside a Container
* discouraged for production containers because these should not be changed manually!
* no SSH needed because Docker provides access into containers, see below

=== Starting a Container Interactively
----
docker container run --name first-container -it nginx bash
----
* t for pseudo TTY (simulate terminal)
* i for interactive (keep STDIN open for commands)
* 'bash' for specifying command that should be run instead of the standard command; bash is a common shell used in
many containers. Exit with 'exit'.

To demonstrate that containers are persistent, let's change a container by installing _curl_ in it:

----
docker container run --name my-ubuntu -it ubuntu
----
* Ubuntus default command is bash, hence no need to specify it

The above should download Ubuntu and start the bash of the container.

*Within the Ubuntu-container*, _curl_ is not installed yet:

----
curl --help
----
----
root@91759829ee87:/# curl --help
bash: curl: command not found
----

Let's install it:
----
apt-get update
apt-get install -y curl
----

Curl can now be used to get websites:
----
curl https://stevenschwenke.de
----

Exit container:
----
exit
----

Start container again:
----
docker container start -ai my-ubuntu
----
*Notice the slightly different syntax "ai" for "attach interactive" instead of "it" for "interactive TTY".*


=== Running Additional Commands in Existing Container
----
docker container exec -it my-ubuntu bash
----
* (container 'my-ubuntu' has to run before executing this)
* 'exec' runs additional process so the container is not stopped when typing 'exit' in shell within container


== Repositories
A short exercise for understanding the local image repository.

Let's download (only) the image for Alpine Linux and delete it afterwards:
----
docker image ls
docker pull alpine
docker image ls
docker image rm alpine
docker image ls
----

== Networks

* Docker containers live inside private virtual networks.
* Each container is connected to a private virtual network called "bridge".
* Each virtual network routes through NAT (Network Address Translation) firewall on host IP so that traffic can be
routed from the host inside the virtual networks to the containers.
* All containers on a virtual network can talk to each other specifying without -p.
* best practice: create one virtual network for each app

=== Docker Container Is Not On Same Network As Host

Start some container to play with:
----
docker container run -p 80:80 --name webhost -d nginx
----

Review ports:
----
docker container port webhost
----

Review IP of container (excerpt from config file that can be shown in full with 'docker container inspect'):
----
docker container inspect --format '{{ .NetworkSettings.IPAddress }}' webhost
----

IP local machine can be reviewed using
----
ifconfig
----

As an example, the container may have the IP 172.17.0.2 while the host has 192.168.8.170 with netmask 255.255.255.240.
That means that the IP addresses are not on the same network. The usable host IP range of the network is 192.168.8
.161 to 192.168.8.174, which does not include 172.17.0.2. This is easy to spot considering the netmask beginning with
255 which means that the first part of the IP is reserved for the network and hence has to be 192 for all hosts on
this network. To experiment with subnet addressing, https://www.calculator.net/ip-subnet-calculator.html[the IP
Subnet Calculator].


=== Creating Networks and Connecting Containers
(Make sure the nginx started in the previous part is still running.)

==== Listing All Networks
----
docker network ls
----
* 'bridge'-network is default docker virtual network to NAT behind host IP

==== Inspect Network to See Which Containers are Connected
----
docker network inspect bridge
----
* should list the container of the nginx under 'Containers:'
* default network to start containers in

----
docker network inspect host
----
* should not have any container connected to it right now
* containers in host network are directly in the network of the host, removing benefits of
containerization

----
docker network inspect none
----
* should not have any container connected to it right now
* for containers with disabled networking

==== Creating A Network and Connect Container to it
First, create a new network:
----
docker network create my_app_net
----
Then, create new container and connect it directly in the network:
----
docker container run -d --name new_nginx --network my_app_net nginx
docker network inspect my_app_net
----
Also, existing containers may be connected to a network:
----
docker network connect my_app_net webhost
----
Syntax for this is 'docker network connect [OPTIONS] NETWORK CONTAINER

Now, there are two containers connected to the network 'my_app_net':
----
docker network inspect my_app_net
----

Disconnect both of the containers:
----
docker network disconnect my_app_net webhost
docker network disconnect my_app_net new_nginx
----

Now, container 'webhost' is still connected to network 'bridge' and container 'new_nginx' is connected to no network
at all:
----
docker container inspect webhost
docker container inspect new_nginx
----

A container can also be connected to multiple networks, so let's connect 'webhost' to 'my_app_net':
----
docker network connect webhost my_app_net
----

Make sure to connect your running containers back to 'bridge' and remove network my_app_net with
----
docker network disconnect my_app_net webhost
docker network disconnect my_app_net new_nginx
docker network connect bridge webhost
docker network connect bridge new_nginx
docker network rm my_app_net
----


==== Resolving Container Addresses with DNS

Within a network **other than 'bridge'**, containers are DNS-resolved by their names. Hence, no manual name resolving
is necessary and IPs are to be avoided.

Containers in the default network 'bridge' could be linked together but it's easier to create a new network that
offers DNS by default.


==== Docker Networks Have Default Security
* communication between containers never leaves host
* all ports closed by default and have to be exposed manually


== Images
* binaries the application needs
* kernel and drivers provided by host
* https://hub.docker.com[hub.docker.com] is main source of images
* official images named 'official' and without user in name (normally '[account name]/[image]'), for example 'nginx'
* official images checked by Docker (quality, documentation)
* best practice to start with official images
* pull image from remote registry, so it is available on local machine:
----
docker pull nginx
----
* get information (explanations below) about image:
----
docker image inspect nginx
----
=> With 'docker image inspect', the possible mappable ports can be reviewed, see "ExposedPorts" in the output.

=== Tags
* tag = pointer to a specific image commit in the repository, created when building the image
* tags can be used to reference the exact image:
----
docker pull nginx:1.11
----
* one image may have multiple tags: 'latest', '1', '1.11.9', '1.11' and '1.11.9-alpine' that all reference the exact
same image (column IMAGE ID)
** 'latest' = special tag showing this version is the most recent one. If no tag is given when referencing image,
'latest' is assumed.
** '1', '1.11' and '1.11.9' = version numbers that can be used to reference major, minor and bugfix releases
** '1.11.9-alpine' = this version uses base image Alpine (sometimes, default images are bigger because they use
bigger base images like Ubuntu)
* images with different tags listed in multiple lines with 'image ls':
----
$ docker pull nginx
$ docker pull nginx:1.21.3
$ docker pull nginx:1.21.3-alpine
$ docker image ls
REPOSITORY                            TAG             IMAGE ID       CREATED        SIZE
nginx                                 1.21.3          87a94228f133   3 weeks ago    133MB
nginx                                 latest          87a94228f133   3 weeks ago    133MB
nginx                                 1.21.3-alpine   513f9a9d8748   8 weeks ago    22.9MB
----
* official images can be found under https://hub.docker.com/search?type=image["explore" in Docker Hub]
* some experimentation with tags (Account at Docker Hub needed):
----
$ docker login
Authenticating with existing credentials...
Login Succeeded

$ docker image ls
REPOSITORY                            TAG             IMAGE ID       CREATED        SIZE
nginx                                 1.21.3          87a94228f133   3 weeks ago    133MB
nginx                                 latest          87a94228f133   3 weeks ago    133MB
nginx                                 1.21.3-alpine   513f9a9d8748   8 weeks ago    22.9MB

$ docker image tag nginx stevenschwenke/nginx

$ docker image ls
REPOSITORY                            TAG             IMAGE ID       CREATED        SIZE
nginx                                 1.21.3          87a94228f133   3 weeks ago    133MB
nginx                                 latest          87a94228f133   3 weeks ago    133MB
stevenschwenke/nginx                  latest          87a94228f133   3 weeks ago    133MB
nginx                                 1.21.3-alpine   513f9a9d8748   8 weeks ago    22.9MB

$ docker image push stevenschwenke/nginx
Using default tag: latest
The push refers to repository [docker.io/stevenschwenke/nginx]
9959a332cf6e: Mounted from library/nginx
f7e00b807643: Mounted from library/nginx
f8e880dfc4ef: Mounted from library/nginx
788e89a4d186: Mounted from library/nginx
43f4e41372e4: Mounted from library/nginx
e81bff2725db: Mounted from library/nginx
latest: digest: sha256:7250923ba3543110040462388756ef099331822c6172a050b12c7a38361ea46f size: 1570

$ docker image tag stevenschwenke/nginx stevenschwenke/nginx:someTag

$ docker image ls
REPOSITORY                            TAG             IMAGE ID       CREATED        SIZE
nginx                                 1.21.3          87a94228f133   3 weeks ago    133MB
nginx                                 latest          87a94228f133   3 weeks ago    133MB
stevenschwenke/nginx                  latest          87a94228f133   3 weeks ago    133MB
stevenschwenke/nginx                  someTag         87a94228f133   3 weeks ago    133MB
nginx                                 1.21.3-alpine   513f9a9d8748   8 weeks ago    22.9MB

$ docker image push stevenschwenke/nginx:someTag
The push refers to repository [docker.io/stevenschwenke/nginx]
9959a332cf6e: Layer already exists
f7e00b807643: Layer already exists
f8e880dfc4ef: Layer already exists
788e89a4d186: Layer already exists
43f4e41372e4: Layer already exists
e81bff2725db: Layer already exists
someTag: digest: sha256:7250923ba3543110040462388756ef099331822c6172a050b12c7a38361ea46f size: 1570

$ docker logout
----

=== Layers
* images consists of layers, where every layer is a command
* layers visible with:
----
docker history nginx:latest
----
----
$ docker history nginx:latest
IMAGE          CREATED       CREATED BY                                      SIZE      COMMENT
87a94228f133   3 weeks ago   /bin/sh -c #(nop)  CMD ["nginx" "-g" "daemonâ€¦   0B
<missing>      3 weeks ago   /bin/sh -c #(nop)  STOPSIGNAL SIGQUIT           0B
<missing>      3 weeks ago   /bin/sh -c #(nop)  EXPOSE 80                    0B
<missing>      3 weeks ago   /bin/sh -c #(nop)  ENTRYPOINT ["/docker-entrâ€¦   0B
<missing>      3 weeks ago   /bin/sh -c #(nop) COPY file:09a214a3e07c919aâ€¦   4.61kB
<missing>      3 weeks ago   /bin/sh -c #(nop) COPY file:0fd5fca330dcd6a7â€¦   1.04kB
<missing>      3 weeks ago   /bin/sh -c #(nop) COPY file:0b866ff3fc1ef5b0â€¦   1.96kB
<missing>      3 weeks ago   /bin/sh -c #(nop) COPY file:65504f71f5855ca0â€¦   1.2kB
<missing>      3 weeks ago   /bin/sh -c set -x     && addgroup --system -â€¦   64MB
<missing>      3 weeks ago   /bin/sh -c #(nop)  ENV PKG_RELEASE=1~buster     0B
<missing>      3 weeks ago   /bin/sh -c #(nop)  ENV NJS_VERSION=0.6.2        0B
<missing>      3 weeks ago   /bin/sh -c #(nop)  ENV NGINX_VERSION=1.21.3     0B
<missing>      3 weeks ago   /bin/sh -c #(nop)  LABEL maintainer=NGINX Doâ€¦   0B
<missing>      3 weeks ago   /bin/sh -c #(nop)  CMD ["bash"]                 0B
<missing>      3 weeks ago   /bin/sh -c #(nop) ADD file:910392427fdf089bcâ€¦   69.3MB
----
* existing layers can be used to build upon, for example multiple applications in different images may use Ubuntu as
a base layer image which is why it has to be downloaded only once.

==== Analyze layers with dive
* https://github.com/wagoodman/dive/[Dive]
* start dive as Docker container and analyze httpd:2.4:
----
docker run --rm -it -v /var/run/docker.sock:/var/run/docker.sock wagoodman/dive httpd:2.4
----

== Dockerfiles
* = file named "Dockerfile" used to build image
* Layers in Dockerfiles:
** Dockerfile contains set of instructions / commands / directives
** every command run will create a new image layer, except for when multiple commands are linked with "&&" (only one
layer is created then), like when creating the new user in the example below where 'echo', creating the group and the
user should all be in one layer.
** Order maters: As soon as one line is different from subsequent builds, all layers above that line are build anew,
too. Hence, it's a good idea to copy the often-changing application files into the image as late / down in the
Dockerfile as possible. Top of the Dockerfile: Stuff that changes less. Bottom of the Dockerfile: Stuff that changes
more.
* Example Dockerfile taken from https://github.com/msgoat/cxp-dox-home/blob/master/docs/docker/docker_dockerfile_2_container_by_example.md[msg Cloud Expert Program]:

----
FROM adoptopenjdk/openjdk11:x86_64-alpine-jre-11.0.6_10

LABEL maintainer="${yourUserIdOrEmail}" \
        group.msg.at.cloud.cnj-hello-backend-spring.project="CXP" \
        group.msg.at.cloud.cnj-hello-backend-spring.version="3.0.0" \
        group.msg.at.cloud.cnj-hello-backend-spring.description="Simplest possible cloud native java backend based on Spring Boot"

ENV JAVA_OPTS="" \
    DOCKER_JAVA_OPTS="" \
    SPRING_JAVA_OPTS="" \
    SPRING_PROFILES_ACTIVE="default" \
    CNAP_CLOUD="local"

RUN echo "adding run user spring to system" \
    && addgroup -S spring -g 1000 \
    && adduser -S spring -u 1000 -G spring

COPY *.jar /home/spring/
COPY docker-entrypoint.sh /home/spring/

RUN chown -R spring:spring /home/spring \
    && chmod u+x /home/spring/docker-entrypoint.sh

USER spring

EXPOSE 8080

ENTRYPOINT ["/home/spring/docker-entrypoint.sh"]
CMD ["java"]
----

* first directive: "FROM". Can also be "FROM scratch" which builds image as a Base-Image.
* "RUN" to execute commands while building the image, for example "RUN apt-get install httpd" to setup the system.
Multi-line commands with "&&".
* "ENV" = environment variables, for example "ENV JAVA_HOME=/home/bla/myjava". Can be overridden when starting
container with "docker run -d -e MYSQL_PASSWORD=geheim myImage:1.0"
* "ADD" to copy files from host into image, for example "ADD /var/archive.tgz /var/" - archive-files will be extracted in target directory. Also possible with URIs: "ADD https://bla/index.html /tmp/"
* "EXPOSE" to expose ports, for example "EXPOSE 53/udp". Attention: dockerfile is only documentation, ports have to
be mapped at container start with "docker run -p"
* "USER" to execute commands by a certain user
* "ENTRYPOINT" to define what should be done after container start. Best-practice: EXEC-form instead of Shell-Form.
* "CMD" is executed when launching the image, for example to start processes within the container
* process of application should be run by separate user, see above "adding run user spring to system" and "USER spring"
* build image-file from remote dockerfile:
----
docker build -t [Registry]/[Image-Name]:[Tag] [path to dockerfile]
----
* build image-file from local dockerfile:
----
docker build -t stevenschwenke/mynginx .
----
* builds image file with tag 1.0.0:
----
docker build -t bla:1.0.0 /home/bla/Dockerfile
----
* remove dangling images, see https://nickjanetakis.com/blog/docker-tip-31-how-to-remove-dangling-docker-images[this article]:
----
docker system prune
----
* Build Context (folder in which docker build is executed) should be as small as possible by either placing it in a
separate folder (from rest of project) or using a .dockerignore -file.

=== Best Practices for Dockerfiles
* don't ever use 'latest' for base image, instead pin a certain version to achieve more stability + pin versions for installed software, too!
* note versions of installed software at the very top as environment variable (ENV)
* "one concern per container"

== Persisting Data: Docker Volumes Mechanism
* container not supposed to be altered when running, immutable and ephemeral (= containers should at any given time
be disposable)
* question: How to persist data?
* separation of concerns: no data in containers!
* solutions in Docker: Volumes and Bind Mounts

=== Docker Volumes
* = make special location outside of container's file system
* in Dockerfile, assign a folder that can be linked with an external folder on host system so that data can outlive
lifetime of container (on example of mysql:latest) :
----
...
VOLUME /var/lib/mysql
...
----
* see volume mount point with
----
$ docker image inspect mysql
...
        "Config": {
...
            "Volumes": {
                "/var/lib/mysql": {}
            },
----
* when running mysql server (without specifying volume!), directory is created:
----
$ docker container run -d --name mysql -e MYSQL_ALLOW_EMPTY_PASSWORD=True mysql
$ af85...
$ docker container inspect mysql
...
        "Mounts": [
            {
                "Type": "volume",
                "Name": "84e2b17e24076fc9f5884e2aea6374638d5094b5d89d52e970730c1f077201d7",
                "Source": "/var/lib/docker/volumes/84e2b17e24076fc9f5884e2aea6374638d5094b5d89d52e970730c1f077201d7/_data",
                "Destination": "/var/lib/mysql",
                "Driver": "local",
                "Mode": "",
                "RW": true,
                "Propagation": ""
            }
        ],
...
$ docker volume ls
DRIVER    VOLUME NAME
local     84e2b17e24076fc9f5884e2aea6374638d5094b5d89d52e970730c1f077201d7
----
* note: when using Windows, mentioned folder is not where it is supposed to be; that just works with Linux

==== Named Volumes
* name volume to get rid of auto-generated name:
----
$ docker container run -d --name mysql -e MYSQL_ALLOW_EMPTY_PASSWORD=True -v mysqldatabase:/var/lib/mysql mysql
----
* that way, re-using volumes easier
* show all existing volumes:
----
docker volume ls
----
* possible to start multiple containers with same volume (share that directory)
* creating volume (before using it in 'run'):
----
$ docker volume create
----
* copy files from container to local:
----
docker cp [container-id]:[path in container] [local path]
----


=== Bind Mounts
* = link container directory to host directory
* easy example: start a webserver with current directory as source directory for files to serve (will serve index.html in that directory):
----
docker run -d --name stevens-httpd -p 8003:80 -v ${PWD}:/usr/local/apache2/htdocs/ httpd:2.4
----


== Walkthrough: From Sourcecode to Container

1. Build with Maven or Gradle / Wrapper
2. Create Image with

    docker build -t stevenschwenke/myapp:latest .

3. Create container and configure names and ports with

    docker run -p 8080:8080 --name stevensapp stevenschwenke/myapp

4. Former command runs container; can be stopped with

    docker stop stevensapp

5. Start container again with

    docker start stevensapp

6. Delete container with

    docker rm stevensapp

7. Delete image with

    docker rmi stevenschwenke/myapp

== Fabric8
* https://github.com/fabric8io/docker-maven-plugin
* Maven-plugin to build and run docker from Maven
* typical command to build current project as docker image:
----
mvn clean package docker:build
----
* creates image in local repository so it is visible with "docker images"
* Alternative for Gradle: https://github.com/Transmode/gradle-docker

== Best Practices
=== Security
* Docker runs with root on host system, so be careful on what images you pull from Docker Hub! Don't execute random code from the internet! Instead, use official images only.
* Docker does not necessarily need to run in root mode: If no custom networks are used, you may use https://docs.docker.com/engine/security/rootless/[the rootless mode].
* Scan repos, for example with https://snyk.io[Snyk] or https://github.com/aquasecurity/trivy[Trivy]
* Discover "bad behavior" with https://sysdig.com/opensource/falco/[Falco]

=== Logging
* route all logging to stdout and stderr to have Docker handle the logs instead of just writing a file within a
container
----
RUN ln -sf /dev/stdout /var/log/nginx/access.log \
	&& ln -sf /dev/stderr /var/log/nginx/error.log
----

=== Keep System Clean
* see space usage
----
docker system df
----
* clean up dangling images (= images that have been build but a newer version was build since then):
----
docker image prune
----
* remove all images not in use (= no containers from that image)
----
docker image prune -a
----
* clean up everything:
----
docker system prune
----


== Docker-Compose
* = Tool for multi-container Docker systems
* sufficient for small and medium-sized applications
* example docker-compose.yml from https://docs.docker.com/compose/wordpress/[Wordpress]:

[source,yml]
----
version: '3.3'

services:
   db:
     image: mysql:5.7
     volumes:
       - db_data:/var/lib/mysql
     restart: always
     environment:
       MYSQL_ROOT_PASSWORD: somewordpress
       MYSQL_DATABASE: wordpress
       MYSQL_USER: wordpress
       MYSQL_PASSWORD: wordpress

   wordpress:
     depends_on:
       - db
     image: wordpress:latest
     ports:
       - "8000:80"
     restart: always
     environment:
       WORDPRESS_DB_HOST: db:3306
       WORDPRESS_DB_USER: wordpress
       WORDPRESS_DB_PASSWORD: wordpress
       WORDPRESS_DB_NAME: wordpress
volumes:
    db_data: {}
----

* "depends_on" causes container to be started after dependent containers have been started, but not necessarily finished starting! Hence: Race-condition possible. Workaround: "restart: always" will restart the container as often as needed to wait for dependent containers. See https://docs.docker.com/compose/compose-file/#depends_on
* (see above) Fabric8 (Maven-plugin to start Docker from within Maven) will wait up to a specified  timeout for dependent containers to start

* another example: nginx in front of httpd from https://github
.com/BretFisher/udemy-docker-mastery/tree/main/compose-sample-2[Bret Fisher's Udemy Docker Mastery Course], enhanced with 'content'-folder for custom html pages:

[source, yml]
----
version: '3'

services:
  proxy:
    image: nginx:1.13 # this will use the latest version of 1.13.x
    ports:
      - '80:80' # expose 80 on host and sent to 80 in container
    volumes:
      - ./nginx.conf:/etc/nginx/conf.d/default.conf:ro
      - ./content:/usr/local/apache2/htdocs/
  web:
    image: httpd  # this will use httpd:latest
    volumes:
      - ./content:/usr/local/apache2/htdocs
----

* "docker compose"-commands have to be executed from directory where docker-compose-file is
* start stack in current terminal (extensive logs!):
----
docker-compose up
----
* start stack as demon (no logs):
----
docker-compose up -d
----
* shut down all containers inside the docker-compose-file:
----
docker-compose down
----
* show running containers:
----
docker-compose ps
----
* list running services:
----
docker-compose top
----
* Docker compose understands dot-notation for current directory (current directory will be mounted to /site within container):
[source,yml]
----
services:
    ...
    volumes:
        - .:/site
    ...
----

=== Building Container Within Compose-File
* from https://github.com/BretFisher/udemy-docker-mastery/blob/main/compose-sample-3/docker-compose.yml[Bret Fishers course]

[source,yml]
----
version: '2'

# based off compose-sample-2, only we build nginx.conf into image
# uses sample HTML static site from https://startbootstrap.com/themes/agency/

services:
  proxy:
    build:
      context: .
      dockerfile: nginx.Dockerfile
    image: nginx-custom
    ports:
      - '80:80'
  web:
    image: httpd
    volumes:
      - ./html:/usr/local/apache2/htdocs/
----
* Will first look up image 'nginx-custom' in local repository. If not found, build it with nginx.Dockerfile.
* for future runs, image will be found and not be build automatically; has to be manually deleted from image cache

== Repositories
* default: pull and push images from Docker Hub
* for pushing image to private repository, re-tagging necessary:
----
docker tag hello-world 127.0.0.1:5000/hello-world
docker push 127.0.0.1:5000/hello-world
docker pull 127.0.0.1:5000/hello-world
----
* running private repository locally:
----
docker container run -d -p 5000:5000 --name registry -v $(pwd)/registry-data:/var/lib/registry registry
----

== Multi-Stage Builds
* https://docs.docker.com/develop/develop-images/multistage-build/[See official docs]

== Docker Contexts
* with Docker 19, contexts have been added to the CLI:

----
$ docker context ls
$ docker context create my_context --docker "host=tcp://some_server,ca=some_ca_file,cert=some_cert_file,
key=some_key_file"
$ docker context use my_context
$ docker context use default
----
* that way, the local Docker CLI can communicate with a remote Docker daemon, for example on a testing server
* the old way of doing this would have been
----
$ DOCKER_HOST="tcp://some_server"
----
* short version for single commands:
----
$ docker -c my_context ps
----


== Docker Swarm Mode (Deprecated; use Kubernetes instead!)
* https://docs.docker.com/engine/swarm/
* = built-in solution for container orchestration
* multiple host systems run docker containers that talk to each other, forming a virtual single host out of multiple hosts
* sufficient for smaller businesses

=== Other Options for Container Orchestration:
* Kubernetes (by Google) = for very large-scale organizations
* OpenShift (by Red Hat) = wrapper around Kubernetes, commercial
* Open Shift Origin = open source version of Open Shift
* Mesosphere = orchestration backed by Apache, commercial
* Apache Mesos = open source version of Mesosphere

=== Activating Docker Swarm Mode
* check if docker swarm is active or not via
----
docker info
----
* result:
----
...
Swarm: inactive
...
----
* enable swarm mode:
----
docker swarm init
----
* this
** sets up a private key infrastructure with a root signing certificate for this swarm
** issued a certificate for the first manager node
** creates join tokens for other nodes
** prints join tokens and instructions on how to add other nodes to the swarm
** creates "raft consensus database" to sync nodes, store root cert and other information
* token can be used to join swarm via
----
docker swarm join --token mytoken
----
* print information about docker swarm nodes:
----
docker node ls
----


=== Docker Swarm Topology
* two node types:
** manager
** worker
* manager-nodes run containers like worker-nodes
* manager-nodes use quorum to reprovision failing worker-nodes, hence robustness of swarm
** important: documentation suggests odd number of manager nodes so they can reach a decision
* one manager-node is "leader"
* if leader goes down, another one is selected

=== Setting up a Docker Swarm
The following is an example of how to set up Docker Swarm on multiple hosts.

* Hint when setting up nodes: should talk over public IP instead of cloud-internal IP, hence specify IP when initializing! (can be grabbed from cloud provider web interface)

* node 1: initialize swarm:
----
docker swarm init --advertise-addr 42.42.42.42
----
* => outputs command to add second node

* node 2: join swarm as worker node:
----
docker swarm join --token mylongtoken
----
* node 1: check if worker node is actually in the swarm:
----
docker info
docker node ls
----
* => swarm is active and has two nodes: node 1 as manager and  leader, node 2 as worker
* node 2 cannot execute "node ls" because it's no manager-node!
* node 1: get command to join new manager:
----
docker swarm join-token manager
----
* => creates command for adding new managers
* node 1: get command from manager node to add new worker nodes:
----
docker node join-token worker
----
* => creates command for adding new workers

=== Auto-Assigning new Leader
* nuking current leader-node:
----
ps -ef | grep docker
kill -9 42421
reboot -f
----
* => (if existing) another manager-node will become leader

=== portainer.io
* portainer.io
** = management tool for docker swarm environments
** https://www.portainer.io/installation/[installation]
* will display manageer- and worker-nodes nicely in web UI

=== Services and Service Discovery
* image that runs in Docker swarm mode = "service", see https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/
* commands: https://docs.docker.com/engine/reference/commandline/service/
* created with
----
docker service create
----
* same parameters for "_docker run_" work with "_docker service create_", difference only in "_docker run_" running container as simple docker container on local machine, "_docker service create_" running container as service in swarm
* docker service, for example installed and running portainer, will be discovered automatically, hence: request service from any of the IPs in the cluster, will be automatically forwarded to node that runs service (technical background: Docker Routing Mesh)
* list all services:
-----
docker service ls
-----

==== Docker Overlay Network
* running multiple applications on swarm instead of only one docker host: maybe different parts of application will be running on different hosts of swarm, hence don't "see" each other, hence Docker Overlay Network important to routing
* Docker Overlay Network = virtual network over multiple nodes of a swarm cluster so that containers inside cluster can communicate with each other
* creation of multiple networks possible to constrain communication between services in their own networks

==== Docker Swarm Stacks
* running multiple commands to create services
* extension of docker compose file: add deploy-instructions to existing build-instructions in docker compose file
** _docker compose_ will ignore deploy-instructions
** _docker swarm_ will ignore build-instructions
* new option "_deploy_" in docker compose file:
----
services:
    ...
    mysqldb:
        ...
        networks:
            - database_net
        deploy:
            replicas: 1
    ...
networks:
    rabbit_net:
        driver: overlay
    database_net
        driver: overlay
----
* command to deploy whole stack defined in docker compose file:
----
docker stack deploy -c docker-compose.yml name_of_stack
----

==== Docker Secrets
* available to docker swarm services
* secrets made available inside containers via file system mount at /run/secrets/<secretname>
* commands:
----
docker secret create
docker secret inspect
docker secret ls
docker secret rm
----

== Cookbooks
* See last section "Spring Boot Cookbook" for concrete examples
* explains numerous examples that are available at https://github.com/springframeworkguru

== Further Reading
* https://github.com/veggiemonk/awesome-docker#hosting-images-registries[Awesome Docker Link List] with tons of
material as links